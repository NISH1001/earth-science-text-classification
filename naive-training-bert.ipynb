{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e6c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d247d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1013895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9adb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"data/data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd85b1",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "\n",
    "> **Note**: It seems pandas couldn't read a large chunk of data. It's only able to load 6K data points.\n",
    "I am sure I could have solved this, but the solution is just a crude way to approach the given problem for tagging a description. So, I let it be. (Plus, it was race against time)\n",
    "\n",
    "### Important\n",
    "\n",
    "If we're going to train a BERT-based Language Model, we will only use a subset of the data where\n",
    "the length of the description < 512 (since BERT can only process 512 input tokens at a time).\n",
    "\n",
    "> **NOTE**:\n",
    "- This can be solved by treating classification of single data point as chunks where we could break the long text.\n",
    "- Or, we can use other robust models like [Longformer](https://github.com/allenai/longformer) that can process \n",
    "at max 4096 input characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc54ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_kws(kw_str, level=2):\n",
    "    res = kw_str.split(\",\")\n",
    "    res = map(lambda kw: [_.strip().lower() for _ in kw.split(\">\")], res)\n",
    "    res = map(lambda x: x[level if level<len(x) else len(x)-1], res)\n",
    "    return list(set(res))\n",
    "\n",
    "def load_data(path, level=0):\n",
    "    logger.info(f\"Loading data from {path}. [KW Level={level}]\")\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"desc\"] = df[\"desc\"].apply(str.strip)\n",
    "    df[\"labels\"] = df[\"keywords\"].apply(lambda x: parse_kws(x, level))\n",
    "    df[\"textlen\"] = df[\"desc\"].apply(len)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2663d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 20:43:15.268 | INFO     | __main__:load_data:8 - Loading data from data/data.csv. [KW Level=1]\n"
     ]
    }
   ],
   "source": [
    "DATA = load_data(datapath, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fac9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5999, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like I said, we're only able to load 6K data points which can be fixed in future!\n",
    "DATA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31cfbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "      <th>textlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS 15 minute stream flow data for Kings Cree...</td>\n",
       "      <td>EARTH SCIENCE &gt; TERRESTRIAL HYDROSPHERE &gt; SURF...</td>\n",
       "      <td>[terrestrial hydrosphere]</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This data set contains the VSMOW-SLAP d17O, d1...</td>\n",
       "      <td>EARTH SCIENCE &gt; Solid Earth &gt; Rocks/Minerals &gt;...</td>\n",
       "      <td>[cryosphere, solid earth]</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Digital line graph (DLG) data are digital repr...</td>\n",
       "      <td>EARTH SCIENCE &gt; HUMAN DIMENSIONS &gt; BOUNDARIES ...</td>\n",
       "      <td>[terrestrial hydrosphere, human dimensions]</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 2000 Pilot Environmental Sustainability In...</td>\n",
       "      <td>EARTH SCIENCE &gt; ATMOSPHERE &gt; AIR QUALITY &gt; EMI...</td>\n",
       "      <td>[biological classification, biosphere, land su...</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 2001 Environmental Sustainability Index (E...</td>\n",
       "      <td>EARTH SCIENCE &gt; ATMOSPHERE &gt; AIR QUALITY &gt; EMI...</td>\n",
       "      <td>[biological classification, biosphere, land su...</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  \\\n",
       "0  USGS 15 minute stream flow data for Kings Cree...   \n",
       "1  This data set contains the VSMOW-SLAP d17O, d1...   \n",
       "2  Digital line graph (DLG) data are digital repr...   \n",
       "3  The 2000 Pilot Environmental Sustainability In...   \n",
       "4  The 2001 Environmental Sustainability Index (E...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SURF...   \n",
       "1  EARTH SCIENCE > Solid Earth > Rocks/Minerals >...   \n",
       "2  EARTH SCIENCE > HUMAN DIMENSIONS > BOUNDARIES ...   \n",
       "3  EARTH SCIENCE > ATMOSPHERE > AIR QUALITY > EMI...   \n",
       "4  EARTH SCIENCE > ATMOSPHERE > AIR QUALITY > EMI...   \n",
       "\n",
       "                                              labels  textlen  \n",
       "0                          [terrestrial hydrosphere]       68  \n",
       "1                          [cryosphere, solid earth]      425  \n",
       "2        [terrestrial hydrosphere, human dimensions]      751  \n",
       "3  [biological classification, biosphere, land su...      956  \n",
       "4  [biological classification, biosphere, land su...      989  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45125c9f",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5902c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29b6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883aa66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_labels(df):\n",
    "    df = df.copy()\n",
    "    labels = [l for ls in df[\"labels\"] for l in ls]\n",
    "    uniques = set(labels)\n",
    "    logger.info(f\"{len(uniques)} unique labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5cd2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 20:43:17.303 | INFO     | __main__:analyze_labels:5 - 29 unique labels\n"
     ]
    }
   ],
   "source": [
    "analyze_labels(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d77e6a3",
   "metadata": {},
   "source": [
    "### Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e63a256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 20:43:17.572 | DEBUG    | __main__:<module>:3 - (5999, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3295549258209702, 0.6309384897482914)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data = DATA.copy()\n",
    "_data = _data[_data[\"textlen\"]>0]\n",
    "logger.debug(_data.shape)\n",
    "\n",
    "# BERT can only process 512 sequence length at once\n",
    "# So, what % of text satisfy that pre-condition?\n",
    "len(_data[_data[\"textlen\"] <= 512]) / len(_data), len(_data[_data[\"textlen\"] <= 1024]) / len(_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "018cb82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 3000.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAANcCAYAAAAelGXbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsBUlEQVR4nO3df7Bnd13f8dd7cwEdQcOPNZPcvTuhkqmmdox0xbg4DkJFSH8EW2RhHIk0Ntsa/DFY22hnitrOFKetiK2lG4UhOAobEYaojJgG1NqVH4sgP7WsFLK7CSRCQC0jzrKf/nHP6mXZzf7Ifd9zv/c+HjPfued7zrnffe+dM9+9eeac860xRgAAAABgve2YewAAAAAAtibhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0WJp7gIficY973LjyyivnHgMAAABgy3jXu971p2OMnevxWgsdnq688socPnx47jEAAAAAtoyq+th6vZZL7QAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBZbIjwtr+xOVc3+WF7ZPfePAgAAAGDTWJp7gPVwz7Gj2Xfg0Nxj5OD+vXOPAAAAALBpbIkzngAAAADYfIQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACgRWt4qqqPVtX7quo9VXV4WveYqrqzqj48fX30tL6q6mer6khVvbeqntg5GwAAAAC9NuKMp28dY1wzxtgzPb8lyV1jjKuS3DU9T5JnJrlqetyU5OUbMBsAAAAATea41O76JLdNy7cledaa9a8eq96W5NKqunyG+QAAAABYB93haST5rap6V1XdNK27bIxx77T88SSXTcvLSY6u+d5j07ovUFU3VdXhqjp8//33d80NAAAAwEO01Pz63zzGOF5VX5nkzqr6o7UbxxijqsaFvOAY49YktybJnj17Luh7AQAAANg4rWc8jTGOT1/vS/KGJE9K8olTl9BNX++bdj+eZGXNt++a1gEAAACwgNrCU1V9WVU96tRykqcneX+SO5LcMO12Q5I3Tst3JHn+9Ol21yb5zJpL8gAAAABYMJ2X2l2W5A1VderP+eUxxm9W1TuT3F5VNyb5WJLnTPu/Kcl1SY4k+WySFzTOBgAAAECztvA0xvhIkq87w/pPJnnaGdaPJDd3zQMAAADAxur+VDsAAAAAtinhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACgRXt4qqpLqurdVfXr0/PHV9Xbq+pIVR2sqodP6x8xPT8ybb+yezYAAAAA+mzEGU8/mORDa57/VJKXjjGekOSBJDdO629M8sC0/qXTfgAAAAAsqNbwVFW7kvyDJL8wPa8kT03yummX25I8a1q+fnqeafvTpv0BAAAAWEDdZzz9TJJ/neTk9PyxST49xjgxPT+WZHlaXk5yNEmm7Z+Z9v8CVXVTVR2uqsP3339/4+gAAAAAPBRt4amq/mGS+8YY71rP1x1j3DrG2DPG2LNz5871fGkAAAAA1lHnGU9PTvKPq+qjSV6b1UvsXpbk0qpamvbZleT4tHw8yUqSTNu/IsknG+cD+ALLK7tTVbM/lld2z/2jAAAAWBdL597l4owxfjTJjyZJVT0lyb8aY3xXVf1KkmdnNUbdkOSN07fcMT3//Wn7W8YYo2s+gNPdc+xo9h04NPcYObh/79wjAAAArIuN+FS70/2bJC+qqiNZvYfTK6b1r0jy2Gn9i5LcMsNsAAAAAKyTtjOe1hpj/HaS356WP5LkSWfY5y+TfOdGzAMAAABAvznOeAIAAABgGxCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE9b1PLK7lTV7I/lld1z/ygAAACAmSzNPcCWsmMpVTX3FH9t34FDc4+Qg/v3zj0CAAAAMBPhaT2dPLEpYk8i+AAAAADzc6kdAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeYJtaXtmdqtoUj+WV3XP/OAAAAGiwNPcAwDzuOXY0+w4cmnuMJMnB/XvnHgEAAIAGzngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtFiaewAATrNjKVU19xRJkit2reT40bvnHgMAAFhQwhPAZnPyRPYdODT3FEmSg//yWzZFBBPAAABgMQlPAJzdJolgB/fvnXsEAADgIrjHEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALRYmnsA2G6WV3bnnmNH5x4DAAAA2glPsMHuOXY0+w4cmnuMHNy/d+4RAAAA2OJcagcAAABAC+EJAAAAgBZt4amqvqSq3lFVf1hVH6iqn5jWP76q3l5VR6rqYFU9fFr/iOn5kWn7lV2zAQAAANCv84ynzyV56hjj65Jck+QZVXVtkp9K8tIxxhOSPJDkxmn/G5M8MK1/6bQfAAAAAAuqLTyNVX8xPX3Y9BhJnprkddP625I8a1q+fnqeafvTqqq65gMAAACgV+s9nqrqkqp6T5L7ktyZ5E+SfHqMcWLa5ViS5Wl5OcnRJJm2fybJY8/wmjdV1eGqOnz//fd3jg8AAADAQ9AansYYnx9jXJNkV5InJfnqdXjNW8cYe8YYe3bu3PlQXw4AAACAJhvyqXZjjE8neWuSb0pyaVUtTZt2JTk+LR9PspIk0/avSPLJjZgPAAAAgPXX+al2O6vq0mn5S5N8W5IPZTVAPXva7YYkb5yW75ieZ9r+ljHG6JoPAAAAgF5L597lol2e5LaquiSrgev2McavV9UHk7y2qv5DkncnecW0/yuS/GJVHUnyqSTPbZwNAAAAgGZt4WmM8d4kX3+G9R/J6v2eTl//l0m+s2seAAAAADbWhtzjCQAAAIDtR3gCAAAAoIXwBAAAAECLzpuLw6axvLI79xw7OvcYAAAAsK0IT2wL9xw7mn0HDs09RpLk4P69c48AAAAAG8KldgAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQIvzCk9V9eTzWQcAAAAAp5zvGU//9TzXAQAAAECSZOnBNlbVNyXZm2RnVb1ozaYvT3JJ52AAAAAALLYHDU9JHp7kkdN+j1qz/s+SPLtrKAAAAAAW34OGpzHG7yT5nap61RjjYxs0EwAAAABbwLnOeDrlEVV1a5Ir137PGOOpHUMBAAAAsPjONzz9SpL/keQXkny+bxxgW9qxlKqaewoAAADW2fmGpxNjjJe3TgJsXydPZN+BQ3NPkYP79849AgAAwJay4zz3+7Wq+r6quryqHnPq0ToZAAAAAAvtfM94umH6+iNr1o0kf2t9xwEAAABgqziv8DTGeHz3IAAAAABsLecVnqrq+WdaP8Z49fqOAwAAAMBWcb6X2n3DmuUvSfK0JH+QRHgCAAAA4IzO91K771/7vKouTfLajoEAAAAA2BrO91PtTvf/krjvEwAAAABndb73ePq1rH6KXZJckuRrktzeNRQAAAAAi+987/H0n9csn0jysTHGsYZ5AAAAANgizutSuzHG7yT5oySPSvLoJH/VORQAAAAAi++8wlNVPSfJO5J8Z5LnJHl7VT27czAAAAAAFtv5Xmr3b5N8wxjjviSpqp1J/meS13UNBgAAAMBiO99PtdtxKjpNPnkB3wsAAADANnS+Zzz9ZlW9Oclrpuf7krypZyQAAAAAtoIHDU9V9YQkl40xfqSq/kmSb542/X6SX+oeDgAAAIDFda4znn4myY8myRjj9UlenyRV9Xenbf+ocTYAAAAAFti57tN02RjjfaevnNZd2TIRAAAAAFvCucLTpQ+y7UvXcQ4AAAAAtphzhafDVfXPT19ZVd+b5F09IwEAAACwFZzrHk8/lOQNVfVd+ZvQtCfJw5N8R+NcAAAAACy4Bw1PY4xPJNlbVd+a5Gun1b8xxnhL+2QAAAAALLRznfGUJBljvDXJW5tnAQAAAGALOdc9ngAAAADgoghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBwAJaXtmdqpr9sbyye+4fBQAAm9jS3AMAABfunmNHs+/AobnHyMH9e+ceAQCATcwZTwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaLE09wAAcE47llJVc0+RJLli10qOH7177jEAAGAhCE8AbH4nT2TfgUNzT5EkObh/79wjAADAwnCpHQAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAi6W5BwCAhbJjKVU19xQAALAQhCcAuBAnT2TfgUNzT5GD+/fOPQIAAJyTS+0AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAK2WV3anqmZ/LK/snvtHAQDbzlLXC1fVSpJXJ7ksyUhy6xjjZVX1mCQHk1yZ5KNJnjPGeKCqKsnLklyX5LNJvmeM8Qdd8wEAsDHuOXY0+w4cmnuMHNy/d+4RAGDb6Tzj6USSHx5jXJ3k2iQ3V9XVSW5JctcY46okd03Pk+SZSa6aHjcleXnjbAAAAAA0awtPY4x7T52xNMb48yQfSrKc5Pokt0273ZbkWdPy9UlePVa9LcmlVXV513wAAAAA9NqQezxV1ZVJvj7J25NcNsa4d9r08axeipesRqmja77t2LTu9Ne6qaoOV9Xh+++/v29oAAAAAB6S9vBUVY9M8qtJfmiM8Wdrt40xRlbv/3Texhi3jjH2jDH27Ny5cx0nBQAAAGA9tYanqnpYVqPTL40xXj+t/sSpS+imr/dN648nWVnz7bumdQAAAAAsoLbwNH1K3SuSfGiM8dNrNt2R5IZp+YYkb1yz/vm16tokn1lzSR4AAAAAC2ap8bWfnOS7k7yvqt4zrfuxJC9JcntV3ZjkY0meM217U5LrkhxJ8tkkL2icDQAAAIBmbeFpjPF7Seosm592hv1Hkpu75gEAAABgY23Ip9oBAAAAsP0ITwAAAAC06LzHEyQ7lrJ6n3kAAABguxGe6HXyRPYdODT3FDm4f+/cIwAAAMC241I7AAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoszT0AALDAdiylquaeIklyxa6VHD9699xjAACwhvAEAFy8kyey78ChuadIkhzcv3fuEQAAOI1L7QAAAABoITwBAAAA0EJ4AgAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0EJ4AgAAAKDF0twDAACsix1Lqaq5p8gVu1Zy/Ojdc48BALApCE8AwNZw8kT2HTg09xQ5uH/v3CMAAGwaLrUDAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAFhAyyu7U1WzP5ZXds/9o2AT86l2AAAAsIDuOXbUJ7qy6TnjCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQIuluQcAANhSdiylquaeIlfsWsnxo3fPPQYAsM0JTwAA6+nkiew7cGjuKXJw/965RwAAcKkdAAAAAD2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAECLpbkHAACgwY6lVNXcUwAA25zwBACwFZ08kX0HDs09RZLk4P69c48AAMzEpXYAAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQoi08VdUrq+q+qnr/mnWPqao7q+rD09dHT+urqn62qo5U1Xur6oldcwEAAACwMTrPeHpVkmectu6WJHeNMa5Kctf0PEmemeSq6XFTkpc3zgUAAADABmgLT2OM303yqdNWX5/ktmn5tiTPWrP+1WPV25JcWlWXd80GAAAAQL+NvsfTZWOMe6fljye5bFpeTnJ0zX7HpnUAAAAALKjZbi4+xhhJxoV+X1XdVFWHq+rw/fff3zAZAAAAAOtho8PTJ05dQjd9vW9afzzJypr9dk3rvsgY49Yxxp4xxp6dO3e2DgsAAADAxdvo8HRHkhum5RuSvHHN+udPn253bZLPrLkkDwAAAIAFtNT1wlX1miRPSfK4qjqW5MVJXpLk9qq6McnHkjxn2v1NSa5LciTJZ5O8oGsuAAAAADZGW3gaYzzvLJuedoZ9R5Kbu2YBAAAAYOPNdnNxAAAAALY24QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAABgm1pe2Z2qmv2xvLJ77h8FAE2W5h4AAACYxz3HjmbfgUNzj5GD+/fOPQIATZzxBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABauLk4AADbw46lVNXcUyRJrti1kuNH7557DABoJzwBALA9nDyxKT7BLfEpbgBsHy61AwAAAKCF8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAAAAALQQngAAAABoITwBAAAA0GJp7gEAAGDb2bGUqpp7CgBoJzwBAMBGO3ki+w4cmnuKHNy/d+4RANjiXGoHAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaCE8AQAAANBCeAIAAACghfAEAAAAQIuluQcAAAC2uR1Lqaq5p0iSXLFrJceP3j33GABbhvAEAADM6+SJ7DtwaO4pkiQH9++dewSALcWldgAAAAC0EJ4AAAAAaOFSOwAAgFM2yf2m3GsK2CqEJwAAgFM2yf2m3GsK2CpcagcAAABAC+EJAAAAgBbCEwAAAJve8sruVNXsj+WV3XP/KGChuMcTAAAAm949x466/xYsIGc8AQAAANBCeAIAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0EJ4AAAAAaLE09wAAAACwMHYsparmngIWhvAEAAAA5+vkiew7cGjuKZIkB/fvnXsEOCeX2gEAAADQwhlPAAAAnNXyyu7cc+zo3GMAC0p4AgAA4KzuOXZ0U1xa5rIyWEwutQMAAACghfAEAAAAQAvhCQAAAIAWwhMAAAAALYQnAAAAAFoITwAAAAC0WJp7AAAAAE6zYylVNfcUAA+Z8AQAALDZnDyRfQcOzT1FkuTg/r1zjwAsMJfaAQAAAKyj5ZXdqarZH8sru+f+UTjjCQAAAGA93XPs6KY4a3EznLHojCcAAAAAWjjjCQAAALh4m+Rm+FfsWsnxo3fPPQanEZ4AAACAi7dJboa/GS4r44u51A4AAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGghPAEAAADQQngCAAAAoIXwBAAAAEAL4QkAAACAFktzDwAAAABAgx1LqapZRxCeAAAAgMW3CSLLpnPyRPYdOHTB33Zw/951G0F4AgAAABbfRUaWDusZbhadezwBAAAA0GJThaeqekZV/XFVHamqW+aeBwAAAICLt2nCU1VdkuTnkjwzydVJnldVV887FQAAAAAXa9OEpyRPSnJkjPGRMcZfJXltkutnngkAAACAi1RjjLlnSJJU1bOTPGOM8b3T8+9O8o1jjBeett9NSW6ann5tkvdv6KCw8R6X5E/nHgKaOc7ZDhznbAeOc7YDxznbwd8eYzxqPV5o4T7Vboxxa5Jbk6SqDo8x9sw8ErRynLMdOM7ZDhznbAeOc7YDxznbQVUdXq/X2kyX2h1PsrLm+a5pHQAAAAALaDOFp3cmuaqqHl9VD0/y3CR3zDwTAAAAABdp01xqN8Y4UVUvTPLmJJckeeUY4wPn+LZb+yeD2TnO2Q4c52wHjnO2A8c524HjnO1g3Y7zTXNzcQAAAAC2ls10qR0AAAAAW4jwBAAAAECLhQ1PVfWMqvrjqjpSVbfMPQ9crKr6aFW9r6rec+ojK6vqMVV1Z1V9ePr66Gl9VdXPTsf9e6vqifNOD2dXVa+sqvuq6v1r1l3wsV1VN0z7f7iqbpjj7wJnc5bj/Mer6vj0vv6eqrpuzbYfnY7zP66qb1+z3u81bEpVtVJVb62qD1bVB6rqB6f13s/ZMh7kOPd+zpZRVV9SVe+oqj+cjvOfmNY/vqrePh2zB6cPe0tVPWJ6fmTafuWa1zrj8X82CxmequqSJD+X5JlJrk7yvKq6et6p4CH51jHGNWOMPdPzW5LcNca4Ksld0/Nk9Zi/anrclOTlGz4pnL9XJXnGaesu6NiuqsckeXGSb0zypCQvPvUfN7BJvCpffJwnyUun9/VrxhhvSpLpd5XnJvk70/f896q6xO81bHInkvzwGOPqJNcmuXk6Pr2fs5Wc7ThPvJ+zdXwuyVPHGF+X5Jokz6iqa5P8VFaP8yckeSDJjdP+NyZ5YFr/0mm/sx7/D/YHL2R4yuo/VkfGGB8ZY/xVktcmuX7mmWA9XZ/ktmn5tiTPWrP+1WPV25JcWlWXzzAfnNMY43eTfOq01Rd6bH97kjvHGJ8aYzyQ5M6c+T/yYRZnOc7P5vokrx1jfG6M8X+THMnq7zR+r2HTGmPcO8b4g2n5z5N8KMlyvJ+zhTzIcX423s9ZONP78l9MTx82PUaSpyZ53bT+9PfzU+/zr0vytKqqnP34P6tFDU/LSY6ueX4sD/7GAJvZSPJbVfWuqrppWnfZGOPeafnjSS6blh37LLoLPbYd8yyqF06XGb1yzVkdjnMW2nSZxdcneXu8n7NFnXacJ97P2UKmM/Pek+S+rP4PgD9J8ukxxolpl7XH7F8fz9P2zyR5bC7iOF/U8ARbyTePMZ6Y1VNyb66qb1m7cYwxshqnYEtxbLOFvTzJV2X1NPZ7k/yXWaeBdVBVj0zyq0l+aIzxZ2u3eT9nqzjDce79nC1ljPH5McY1SXZl9Sylr96IP3dRw9PxJCtrnu+a1sHCGWMcn77el+QNWX0D+MSpS+imr/dNuzv2WXQXemw75lk4Y4xPTL/YnUzy8/mb088d5yykqnpYVv9j/JfGGK+fVns/Z0s503Hu/Zytaozx6SRvTfJNWb0kemnatPaY/evjedr+FUk+mYs4zhc1PL0zyVXT3dcfntUbW90x80xwwarqy6rqUaeWkzw9yfuzejyf+rSXG5K8cVq+I8nzp0+MuTbJZ9ac5g6L4EKP7TcneXpVPXo6vf3p0zrYtE679953ZPV9PVk9zp87fUrM47N68+V3xO81bGLT/TxekeRDY4yfXrPJ+zlbxtmOc+/nbCVVtbOqLp2WvzTJt2X1fmZvTfLsabfT389Pvc8/O8lbpjNcz3b8n9XSg23crMYYJ6rqhVn9x+qSJK8cY3xg5rHgYlyW5A2r/9ZlKckvjzF+s6remeT2qroxyceSPGfa/01JrsvqDdw+m+QFGz8ynJ+qek2SpyR5XFUdy+qnGb0kF3BsjzE+VVX/Pqu/yCXJT44xzvdGztDuLMf5U6rqmqxeevTRJPuTZIzxgaq6PckHs/oJSjePMT4/vY7fa9isnpzku5O8b7ovSJL8WLyfs7Wc7Th/nvdztpDLk9w2fQLdjiS3jzF+vao+mOS1VfUfkrw7qxE209dfrKojWf0glecmD378n02tBisAAAAAWF+LeqkdAAAAAJuc8AQAAABAC+EJAAAAgBbCEwAAAAAthCcAAAAAWghPAADnUFWXVtX3XeT3XlNV1615/j1V9d/WbzoAgM1LeAIAOLdLk1xUeEpyTZLrzrUTAMBWJDwBAJzbS5J8VVW9p6r+U1X9SFW9s6reW1U/kSRV9R1VdVeturyq/k9V7U7yk0n2Td+7b+2LVtXOqvrV6bXeWVVPntb/eFW9sqp+u6o+UlU/sOF/YwCAdSA8AQCc2y1J/mSMcU2SO5NcleRJWT2b6e9V1beMMd6Q5N4kNyf5+SQvHmPcneTfJTk4xrhmjHHwtNd9WZKXjjG+Ick/TfILa7Z9dZJvn/6cF1fVw7r+cgAAXZbmHgAAYME8fXq8e3r+yKyGqN9N8v1J3p/kbWOM15zHa/39JFdX1annX15Vj5yWf2OM8bkkn6uq+5JcluTY+vwVAAA2hvAEAHBhKsl/HGMcOMO2XUlOJrmsqnaMMU6e47V2JLl2jPGXX/AHrIaoz61Z9fn4vQ0AWEAutQMAOLc/T/KoafnNSf7ZqTOTqmq5qr6yqpaSvDLJ85J8KMmLzvC9p/utrJ4llem1rln/0QEA5iM8AQCcwxjjk0n+d1W9P8m3JfnlJL9fVe9L8rqshqUfS/K/xhi/l9Xo9L1V9TVJ3prVy+m+6ObiSX4gyZ7pJuUfTPIvNuivBACwIWqMMfcMAAAAAGxBzngCAAAAoIXwBAAAAEAL4QkAAACAFsITAAAAAC2EJwAAAABaCE8AAAAAtBCeAAAAAGjx/wGacvGXEknD7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "sns.histplot(data=_data, x=\"textlen\", bins=100).set(xlim=(0, 3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67788577",
   "metadata": {},
   "source": [
    "## MultiLabelEncoder Analysis\n",
    "\n",
    "Since, the problem is a multi-label clasification (if we treat the problem as a classification problem), we need to see if we can encode the labels accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf6d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TO_USE = DATA.copy()\n",
    "DATA_TO_USE = DATA_TO_USE[DATA_TO_USE[\"textlen\"]<=500]\n",
    "DATA_TO_USE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da5e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TO_USE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Now our level 1 keywords are <29 (N=22) classes because we have filtered the data \n",
    "analyze_labels(DATA_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "629d0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = MultiLabelBinarizer()\n",
    "LABELS_ENCODED = LE.fit_transform(DATA_TO_USE[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "352cc93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1930, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 22 classes for level=1 keywords\n",
    "LABELS_ENCODED.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf7c91a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS_ENCODED[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8633343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['active remote sensing', 'agriculture', 'atmosphere',\n",
       "       'biological classification', 'biosphere', 'climate indicators',\n",
       "       'cryosphere', 'data analysis and visualization',\n",
       "       'environmental advisories', 'human dimensions', 'hydrosphere',\n",
       "       'land surface', 'nasa decadal survey', 'none', 'not provided',\n",
       "       'oceans', 'paleoclimate', 'solid earth', 'spectral engineering',\n",
       "       'spectral/engineering', 'sun-earth interactions',\n",
       "       'terrestrial hydrosphere'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LE.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb9c29db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrestrial hydrosphere',),\n",
       " ('cryosphere', 'solid earth'),\n",
       " ('atmosphere',),\n",
       " ('cryosphere', 'terrestrial hydrosphere'),\n",
       " ('biosphere', 'land surface'),\n",
       " ('biosphere', 'human dimensions'),\n",
       " ('atmosphere', 'biosphere', 'human dimensions', 'land surface'),\n",
       " ('atmosphere', 'sun-earth interactions'),\n",
       " ('atmosphere', 'sun-earth interactions'),\n",
       " ('cryosphere', 'land surface')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if inverse works\n",
    "# Note: encoded lables should be 1s and 0s\n",
    "LE.inverse_transform(LABELS_ENCODED[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ddaf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TO_USE[\"labels_encoded\"] = list(LABELS_ENCODED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efaee213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "      <th>textlen</th>\n",
       "      <th>labels_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS 15 minute stream flow data for Kings Cree...</td>\n",
       "      <td>EARTH SCIENCE &gt; TERRESTRIAL HYDROSPHERE &gt; SURF...</td>\n",
       "      <td>[terrestrial hydrosphere]</td>\n",
       "      <td>68</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This data set contains the VSMOW-SLAP d17O, d1...</td>\n",
       "      <td>EARTH SCIENCE &gt; Solid Earth &gt; Rocks/Minerals &gt;...</td>\n",
       "      <td>[solid earth, cryosphere]</td>\n",
       "      <td>425</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30 minute rainfall data for the Konza Prairie</td>\n",
       "      <td>EARTH SCIENCE &gt; ATMOSPHERE &gt; PRECIPITATION &gt; P...</td>\n",
       "      <td>[atmosphere]</td>\n",
       "      <td>45</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This data set provides glacier surface ablatio...</td>\n",
       "      <td>EARTH SCIENCE &gt; Cryosphere &gt; Glaciers/Ice Shee...</td>\n",
       "      <td>[cryosphere, terrestrial hydrosphere]</td>\n",
       "      <td>367</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>This data set provides a fire progression map ...</td>\n",
       "      <td>EARTH SCIENCE &gt; BIOSPHERE &gt; ECOLOGICAL DYNAMIC...</td>\n",
       "      <td>[land surface, biosphere]</td>\n",
       "      <td>415</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 desc  \\\n",
       "0   USGS 15 minute stream flow data for Kings Cree...   \n",
       "1   This data set contains the VSMOW-SLAP d17O, d1...   \n",
       "12      30 minute rainfall data for the Konza Prairie   \n",
       "21  This data set provides glacier surface ablatio...   \n",
       "22  This data set provides a fire progression map ...   \n",
       "\n",
       "                                             keywords  \\\n",
       "0   EARTH SCIENCE > TERRESTRIAL HYDROSPHERE > SURF...   \n",
       "1   EARTH SCIENCE > Solid Earth > Rocks/Minerals >...   \n",
       "12  EARTH SCIENCE > ATMOSPHERE > PRECIPITATION > P...   \n",
       "21  EARTH SCIENCE > Cryosphere > Glaciers/Ice Shee...   \n",
       "22  EARTH SCIENCE > BIOSPHERE > ECOLOGICAL DYNAMIC...   \n",
       "\n",
       "                                   labels  textlen  \\\n",
       "0               [terrestrial hydrosphere]       68   \n",
       "1               [solid earth, cryosphere]      425   \n",
       "12                           [atmosphere]       45   \n",
       "21  [cryosphere, terrestrial hydrosphere]      367   \n",
       "22              [land surface, biosphere]      415   \n",
       "\n",
       "                                       labels_encoded  \n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1   [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "21  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "22  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_TO_USE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff047c61",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed42a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2527ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, Y_train, Y_test = train_test_split(DATA_TO_USE[\"desc\"].to_numpy(), LABELS_ENCODED, test_size=0.1, random_state=42)\n",
    "\n",
    " X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31b20266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1563,), (174,), (193,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c33adaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1563, 22), (174, 22), (193, 22))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce81c7d1",
   "metadata": {},
   "source": [
    "# Create Pytorch Dataset\n",
    "\n",
    "We are using pytorch lightning for the sake of convenience and easy prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90203f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e289800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2198566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c96641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cpu'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3231858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e7c2a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "716acd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagDataset (Dataset):\n",
    "    \"\"\"\n",
    "        Holds the pytorch dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,texts, tags, tokenizer, max_len=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = tags\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        text = self.texts[item_idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length= self.max_len,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False,\n",
    "            return_attention_mask= True,\n",
    "            truncation=True,\n",
    "            return_tensors = 'pt'\n",
    "          )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids ,\n",
    "            'attention_mask': attn_mask,\n",
    "            'label': torch.tensor(self.labels[item_idx], dtype=torch.float)\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91dfb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagDataModule (pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        tokenizer,\n",
    "        batch_size=4,\n",
    "        max_token_len=512\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_text = x_train\n",
    "        self.train_label = y_train\n",
    "        self.val_text = x_val\n",
    "        self.val_label = y_val\n",
    "        self.test_text = x_test\n",
    "        self.test_label = y_test\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self):\n",
    "        self.train_dataset = TagDataset(texts=self.train_text, tags=self.train_label, tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.val_dataset  = TagDataset(texts=self.val_text,tags=self.val_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.test_dataset  = TagDataset(texts=self.test_text,tags=self.test_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader (self.train_dataset, batch_size = self.batch_size,shuffle = True , num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader (self.val_dataset, batch_size= 16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader (self.test_dataset, batch_size= 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8f929",
   "metadata": {},
   "source": [
    "## Huggingface Transformers\n",
    "\n",
    "Setup data and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "709c7512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eac9ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d20900f245c4366b952781fbe9243a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c3b58774b74740908b4c838a38aa4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28daec4ff844b07a6204a49f42b72ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOKENIZER = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# BASE_MODEL = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "BASE_MODEL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09ff9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters that will be use for training\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "MAX_LEN = 512\n",
    "LR = 1e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "584633ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_DATA_MODULE = TagDataModule(\n",
    "    X_train, Y_train,\n",
    "    X_val, Y_val,\n",
    "    X_test, Y_test,\n",
    "    TOKENIZER,\n",
    "    BATCH_SIZE,\n",
    "    MAX_LEN\n",
    ")\n",
    "TAG_DATA_MODULE.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3608c",
   "metadata": {},
   "source": [
    "## Setup Model\n",
    "\n",
    "We're using bert-base-uncased and fine-tune it.\n",
    "\n",
    "We're just replacing the output (classification) layer.\n",
    "\n",
    "```\n",
    "    ...\n",
    "    ...\n",
    "   (pooler): BertPooler(\n",
    "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "      (activation): Tanh()\n",
    "    )\n",
    "  )\n",
    "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
    "  (criterion): BCEWithLogitsLoss()\n",
    ")\n",
    "```\n",
    "\n",
    "### Note\n",
    "- We could in fact put a complex layer after BERT. But I have done it for the sake of simplicity.\n",
    "- As mentioned earlier, we're only using level1 tags as it has the lowest number of classes for which\n",
    "the problem could be solved as **classification problem**.\n",
    "\n",
    "Also, we're using **BCEWithLogitsLoss** becauseo of **multi-label classification**. See: https://discuss.pytorch.org/t/using-bcewithlogisloss-for-multi-label-classification/67011/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "483541c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d1cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6353b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagClassifier(pl.LightningModule):\n",
    "    # Set up the classifier\n",
    "    def __init__(self, base_model=None, n_classes=10, steps_per_epoch=None, n_epochs=5, lr=1e-5 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = base_model or AutoModel.from_pretrained(\"bert-base-uncased\", return_dict=True)\n",
    "        self.classifier = torch.nn.Linear(self.model.config.hidden_size,n_classes)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self,input_ids, attn_mask):\n",
    "        output = self.model(input_ids = input_ids ,attention_mask = attn_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
    "\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('test_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters() , lr=self.lr)\n",
    "        warmup_steps = self.steps_per_epoch//3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,total_steps)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c77ee6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae1f22fde0b40a0a32e5fc5f43b13cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
    "MODEL = TagClassifier(BASE_MODEL, n_classes=22, steps_per_epoch=STEPS_PER_EPOCH,n_epochs=EPOCHS,lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07286489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "# gpu\n",
    "# trainer = pl.Trainer(max_epochs = EPOCHS , gpus = 1, callbacks=[], progress_bar_refresh_rate = 30)\n",
    "trainer = pl.Trainer(max_epochs = EPOCHS, callbacks=[], progress_bar_refresh_rate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff1ab481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docuparadox/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | model      | BertModel         | 109 M \n",
      "1 | classifier | Linear            | 16.9 K\n",
      "2 | criterion  | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.997   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9671913e11547a18ee16df02dcd1380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docuparadox/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80947/3979797082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAG_DATA_MODULE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_dataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         dl_outputs = self.epoch_loop.run(\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mdataloader_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_dataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         )\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, dataloader_iter, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \"\"\"\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_80947/1600947330.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mprog_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_80947/1600947330.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attn_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         )\n\u001b[0;32m--> 991\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    992\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     ):\n\u001b[0;32m--> 401\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nish/Programming/Python/projects/earth-science-text-classification/venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(MODEL, TAG_DATA_MODULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "157b8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_checkpoint(\"model-10.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4248576",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aaf59cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TagClassifier(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "983a08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(MODEL,datamodule=TAG_DATA_MODULE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc70339",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a438f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b6e9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESH = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0335518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, texts, tokenizer, batch_size=1):\n",
    "    # model.eval()\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    input_ids, attention_masks = [], []\n",
    "    for text in texts:\n",
    "        text_encoded = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        None,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length= MAX_LEN,\n",
    "                        padding = 'max_length',\n",
    "                        return_token_type_ids= False,\n",
    "                        return_attention_mask= True,\n",
    "                        truncation=True,\n",
    "                        return_tensors = 'pt'      \n",
    "        )\n",
    "        input_ids.append(text_encoded[\"input_ids\"])\n",
    "        attention_masks.append(text_encoded[\"attention_mask\"])\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    pred_data = TensorDataset(input_ids, attention_masks)\n",
    "    pred_sampler = SequentialSampler(pred_data)\n",
    "    pred_dataloader = DataLoader(pred_data, sampler=pred_sampler, batch_size=batch_size)\n",
    "    pred_outs = []\n",
    "    for batch in pred_dataloader:\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(DEVICE) for t in batch)\n",
    "    \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_attn_mask = batch\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            pred_out = model(b_input_ids,b_attn_mask)\n",
    "            pred_out = torch.sigmoid(pred_out)\n",
    "            # Move predicted output and labels to CPU\n",
    "            pred_out = pred_out.detach().cpu().numpy()\n",
    "        pred_outs.append(pred_out)\n",
    "    return pred_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2091b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "_texts = X_test[:5]\n",
    "_pred_outs = inference(MODEL, _texts, TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b035a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45998588 0.4830769  0.39009407 0.5189705  0.4803717  0.50975114\n",
      " 0.54787636 0.34423095 0.4665581  0.38090274 0.47248274 0.4457833\n",
      " 0.44118464 0.63428545 0.48551884 0.51885164 0.46105388 0.43998215\n",
      " 0.42852473 0.51147026 0.58508766]\n",
      "Level 3, Seasonal climatology, ascending ancillary ('oceans',) ('active remote sensing', 'agriculture', 'atmosphere', 'biological classification', 'biosphere', 'climate indicators', 'cryosphere', 'data analysis and visualization', 'environmental advisories', 'human dimensions', 'hydrosphere', 'land surface', 'nasa decadal survey', 'none', 'not provided', 'oceans', 'solid earth', 'spectral engineering', 'spectral/engineering', 'sun-earth interactions', 'terrestrial hydrosphere')\n",
      "[0.43458444 0.468253   0.37319997 0.50230104 0.4464024  0.5343185\n",
      " 0.5744993  0.35050598 0.48038533 0.3767068  0.48330733 0.44385204\n",
      " 0.43903014 0.6301987  0.49080366 0.5089056  0.472289   0.38934553\n",
      " 0.45917654 0.49289444 0.6152085 ]\n",
      "This data set consists of soil texture classificat ('land surface',) ('active remote sensing', 'agriculture', 'atmosphere', 'biological classification', 'biosphere', 'climate indicators', 'cryosphere', 'data analysis and visualization', 'environmental advisories', 'human dimensions', 'hydrosphere', 'land surface', 'nasa decadal survey', 'none', 'not provided', 'oceans', 'solid earth', 'spectral engineering', 'spectral/engineering', 'sun-earth interactions', 'terrestrial hydrosphere')\n",
      "[0.45967263 0.5170623  0.47785354 0.48826247 0.4609638  0.55078274\n",
      " 0.5492074  0.43491232 0.47281477 0.43128988 0.47965392 0.4664874\n",
      " 0.46903682 0.5824091  0.47335795 0.5301438  0.37067035 0.49094856\n",
      " 0.391878   0.48116767 0.4901301  0.57193106]\n",
      "Level 3 parameters from HIRS/2 and MSU radiances u ('atmosphere',) ('active remote sensing', 'agriculture', 'atmosphere', 'biological classification', 'biosphere', 'climate indicators', 'cryosphere', 'data analysis and visualization', 'environmental advisories', 'human dimensions', 'hydrosphere', 'land surface', 'nasa decadal survey', 'none', 'not provided', 'oceans', 'paleoclimate', 'solid earth', 'spectral engineering', 'spectral/engineering', 'sun-earth interactions', 'terrestrial hydrosphere')\n",
      "[0.43326578 0.47090387 0.3965996  0.49999738 0.46275806 0.51199174\n",
      " 0.5716256  0.36819956 0.49183413 0.38317257 0.49916917 0.44697633\n",
      " 0.42752346 0.6403117  0.4939745  0.49376297 0.31945246 0.4552495\n",
      " 0.3824208  0.44970942 0.50806653 0.56925327]\n",
      "The MOBRGB is a thermal composit Jpeg image produc ('spectral/engineering',) ('active remote sensing', 'agriculture', 'atmosphere', 'biological classification', 'biosphere', 'climate indicators', 'cryosphere', 'data analysis and visualization', 'environmental advisories', 'human dimensions', 'hydrosphere', 'land surface', 'nasa decadal survey', 'none', 'not provided', 'oceans', 'paleoclimate', 'solid earth', 'spectral engineering', 'spectral/engineering', 'sun-earth interactions', 'terrestrial hydrosphere')\n",
      "[0.46741083 0.5153892  0.41679168 0.47886345 0.48208812 0.53508675\n",
      " 0.5640879  0.37932828 0.46834338 0.376555   0.46186325 0.42471308\n",
      " 0.47193676 0.61735106 0.48277336 0.52742964 0.30760702 0.46227384\n",
      " 0.4162476  0.4500161  0.47805354 0.59091914]\n",
      "The objective of this classification is to provide ('land surface',) ('active remote sensing', 'agriculture', 'atmosphere', 'biological classification', 'biosphere', 'climate indicators', 'cryosphere', 'data analysis and visualization', 'environmental advisories', 'human dimensions', 'hydrosphere', 'land surface', 'nasa decadal survey', 'none', 'not provided', 'oceans', 'paleoclimate', 'solid earth', 'spectral engineering', 'spectral/engineering', 'sun-earth interactions', 'terrestrial hydrosphere')\n"
     ]
    }
   ],
   "source": [
    "# If model is properly fine-tuned, this should be accurate\n",
    "for _txt, _yt, _p in zip(_texts, Y_test, _pred_outs.copy()):\n",
    "    _p = _p.flatten()\n",
    "    confs = _p[_p>CONF_THRESH]\n",
    "    _p[_p<CONF_THRESH] = 0\n",
    "    _p[_p>=CONF_THRESH] = 1\n",
    "    \n",
    "    print(confs)\n",
    "    pred_tag = LE.inverse_transform(np.array([_p]))[0]\n",
    "    gt_tag = LE.inverse_transform(np.array([_yt]))[0]\n",
    "    print(_txt[:50], gt_tag, pred_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeefebb",
   "metadata": {},
   "source": [
    "# Custom Evaluation\n",
    "\n",
    "Since, it's a multi-label classification, find the actual \"real\" metric to evaluate is tricky.\n",
    "Might depend on the usecase.\n",
    "\n",
    "The train/val/test loss could also be a good indicator, but at the end, we need to infer\n",
    "the actual labels and figure out if they are correct.\n",
    "\n",
    "For that, I have used a jaccard similarity based metric, which is something similar to IoU for object detection, but for NLP. It's simply *how many of the labels are common* between two sets of labels (GT and PREDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aaf75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1953e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference2(model, tokenizer, texts, gts, threshold=0.3):\n",
    "    _pred_outs = inference(model, texts, tokenizer, batch_size=1)\n",
    "    res = []\n",
    "    for txt, gt, pred in zip(texts, gts, _pred_outs):\n",
    "        p = pred.flatten().copy()\n",
    "        confs = p[p>threshold]\n",
    "        p[p<threshold] = 0\n",
    "        p[p>=threshold] = 1\n",
    "        p = np.array([p])\n",
    "        gt = np.array([gt])\n",
    "        pred_tags = LE.inverse_transform(p)[0]\n",
    "        gt_tags = LE.inverse_transform(gt)[0]\n",
    "        res.append({\"gts\": gt_tags, \"preds\": pred_tags, \"text\": txt, \"confs\": list(confs)})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2e2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard(tokens1, tokens2):\n",
    "    if not tokens1 or not tokens2:\n",
    "        return 0\n",
    "    intersection = set(tokens1).intersection(tokens2)\n",
    "    union = set(tokens1).union(tokens2)\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e70ecb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_jaccard([1, 2], [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0cdeb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_jaccard(model, tokenizer, texts, gts, threshold=0.3):\n",
    "    \"\"\"\n",
    "        Jaccard Evaluation. SIimlar to IoU\n",
    "    \"\"\"\n",
    "    predictions = inference2(model, tokenizer, texts, gts, threshold)\n",
    "    with open(\"inference.json\", \"w\") as f:\n",
    "        json.dump(predictions, f)\n",
    "    metrics = []\n",
    "    for pmap in predictions:\n",
    "        metrics.append(compute_jaccard(pmap[\"gts\"], pmap[\"preds\"]))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "091f1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_jaccard(MODEL, TOKENIZER, X_test[:5], Y_test[:5], threshold=CONF_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a65fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af6a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_jaccard_json(jsonpath):\n",
    "    \"\"\"\n",
    "        In case we have a json dump of the test inference\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    with open(jsonpath) as f:\n",
    "        predictions = json.load(f)\n",
    "    metrics = []\n",
    "    for pmap in predictions:\n",
    "        gts = pmap[\"gts\"]\n",
    "        preds = pmap[\"preds\"]\n",
    "        sim = compute_jaccard(gts, preds)\n",
    "        metrics.append((pmap[\"text\"][:50], gts, preds, sim))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "274929e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = eval_jaccard_json(\"outputs/inference.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0232e7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1543fee80>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sims = [r[-1] for r in res]\n",
    "plt.scatter(range(len(sims)), sims)\n",
    "plt.ylabel(\"jaccard sim\")\n",
    "plt.plot(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4212c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99b0200d",
   "metadata": {},
   "source": [
    "# Further Improvement?\n",
    "\n",
    "This was a very rough approach to the problem as **multi-label** classification.\n",
    "\n",
    "## Approach 2 [Best One?]\n",
    "\n",
    "However, we could also do some representation learning to embed each tags w.r.t text embedding from a LM.\n",
    "\n",
    "I had done a very complex represntation problem 6months back, by implementing the following paper from Google:\n",
    "[Representation Learning for Information Extraction from Form-like Documents](https://research.google/pubs/pub49122/)\n",
    "\n",
    "## Approach 3\n",
    "\n",
    "We could use [Longformer](https://github.com/allenai/longformer) that can have more sequence length.\n",
    "(Or maybe other LMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029862b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
